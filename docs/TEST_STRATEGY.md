# üß™ Test-Strategie - Easter Egg Hunt System

## üìã √úbersicht

Dieses Dokument beschreibt die umfassende Test-Strategie f√ºr das Easter Egg Hunt System. Es definiert Test-Kategorien, Coverage-Requirements, Best Practices und aktuelle Metriken.

## üéØ Test-Philosophie

### Grundprinzipien

1. **Test-Driven Development (TDD)**: Tests werden vor der Implementierung geschrieben
2. **Test-Pyramide**: Viele schnelle Unit-Tests, weniger Integration-Tests, wenige E2E-Tests
3. **Isolation**: Tests sind unabh√§ngig voneinander und k√∂nnen in beliebiger Reihenfolge ausgef√ºhrt werden
4. **Schnelligkeit**: Unit-Tests sollten sehr schnell sein (< 100ms pro Test)
5. **Vertrauensw√ºrdigkeit**: Tests sollten zuverl√§ssig sein und keine Flakiness zeigen

### Test-Pyramide

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    E2E Tests          ‚îÇ ‚Üê ~40 Tests (5%)
                    ‚îÇ   (Integration)       ‚îÇ   Langsam, vollst√§ndige Journeys
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ    Integration Tests       ‚îÇ ‚Üê ~173 Tests (22%)
                  ‚îÇ  (Infrastructure, API)      ‚îÇ   Mittel, Datenbank/Services
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ          Unit Tests                      ‚îÇ ‚Üê ~600 Tests (74%)
            ‚îÇ  (Domain, Application, Controllers)      ‚îÇ   Schnell, isoliert
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Verteilung:**
- **Unit Tests**: ~600 Tests (74%) - Schnell, isoliert, hohe Coverage
- **Integration Tests**: ~173 Tests (21%) - Mittel, Datenbank/API
- **E2E Tests**: ~37 Tests (5%) - Langsam, vollst√§ndige Journeys

**Neue Tests (Fund-Historie):**
- **Repository Integration Tests**: 6 Tests ‚úÖ
- **Service Unit Tests**: 3 Tests ‚úÖ
- **API Controller Tests**: 5 Tests ‚úÖ
- **Web Controller Tests**: 4 Tests ‚úÖ
- **Gesamt**: 18 neue Tests gem√§√ü Testpyramide ‚úÖ

## üìä Aktuelle Test-Metriken

### Test-Statistiken (Stand: Oktober 2025)

| Test-Projekt | Tests | Duration | Status |
|-------------|-------|----------|--------|
| **Domain.Tests** | 203 | ~418ms | ‚úÖ |
| **Application.Tests** | 247 | ~3s | ‚úÖ |
| **Infrastructure.Tests** | 173 | ~7s | ‚úÖ |
| **Api.Tests** | 94 | ~447ms | ‚úÖ |
| **Integration.Tests** | 37 | ~7s | ‚úÖ |
| **Web.Tests** | 69 (5 skipped) | ~577ms | ‚úÖ |
| **GESAMT** | **~810 Tests** | **~7-8s** | ‚úÖ |

### Code Coverage (Stand: Oktober 2025)

| Projekt | Line Coverage | Branch Coverage | Method Coverage | Status |
|---------|--------------|----------------|----------------|--------|
| **Domain** | **89.6%** | 100% | 81.56% | ‚úÖ Ziel: ‚â•80% |
| **Application** | **90.52%** | 90.4% | 82.89% | ‚úÖ Ziel: ‚â•80% |
| **Infrastructure** | **36.28%** | 43.38% | 65.97% | ‚úÖ Ziel: ‚â•25% (Domain ausgeschlossen) |

**Gesamt-Coverage:** 
- **Line Coverage**: ~73% (gewichtet nach Code-Menge)
- **Branch Coverage**: ~86%
- **Method Coverage**: ~78%

### Coverage-Verbesserungen (Phase 5)

**Domain Coverage:**
- Start: 66.4% (52 Tests)
- Ende: 89.6% (203 Tests)
- Verbesserung: +23.2% (+151 Tests)

**Application Coverage:**
- Start: 68.42% (162 Tests)
- Ende: 90.52% (237 Tests)
- Verbesserung: +22.1% (+75 Tests)

**Infrastructure Coverage:**
- Start: 34.04% (115 Tests)
- Ende: 36.28% (173 Tests) - Domain ausgeschlossen
- Verbesserung: +2.24% (+58 Tests)
- **Neue Features:** Fund-Historie mit Filter (6 Repository-Tests) ‚úÖ

## üèóÔ∏è Test-Architektur

### Test-Projekt-Struktur

```
tests/
‚îú‚îÄ‚îÄ EasterEggHunt.Domain.Tests/              # Unit Tests f√ºr Domain
‚îÇ   ‚îú‚îÄ‚îÄ Entities/                            # Entity-Tests
‚îÇ   ‚îî‚îÄ‚îÄ Models/                              # DTO-Tests
‚îú‚îÄ‚îÄ EasterEggHunt.Application.Tests/        # Unit Tests f√ºr Services
‚îÇ   ‚îî‚îÄ‚îÄ Services/                            # Service-Tests mit Moq
‚îú‚îÄ‚îÄ EasterEggHunt.Infrastructure.Tests/    # Integration Tests
‚îÇ   ‚îú‚îÄ‚îÄ Integration/                          # Repository-Integration-Tests
‚îÇ   ‚îú‚îÄ‚îÄ Data/                                # DbContext/SeedData-Tests
‚îÇ   ‚îú‚îÄ‚îÄ Configuration/                       # Config-Tests
‚îÇ   ‚îî‚îÄ‚îÄ IntegrationTestBase.cs               # Basis f√ºr Integration-Tests
‚îú‚îÄ‚îÄ EasterEggHunt.Api.Tests/                 # API Controller Tests
‚îÇ   ‚îî‚îÄ‚îÄ Controllers/                         # Controller-Unit-Tests
‚îú‚îÄ‚îÄ EasterEggHunt.Integration.Tests/          # E2E Tests
‚îÇ   ‚îú‚îÄ‚îÄ Workflows/                           # Workflow-Tests
‚îÇ   ‚îî‚îÄ‚îÄ Helpers/                             # TestWebApplicationFactory
‚îî‚îÄ‚îÄ EasterEggHunt.Web.Tests/                # MVC Controller Tests
    ‚îî‚îÄ‚îÄ Controllers/                         # MVC-Controller-Tests
```

## üéØ Test-Kategorien

### 1. Unit Tests

**Ziel:** Schnelle, isolierte Tests f√ºr einzelne Klassen/Methoden

**Charakteristika:**
- ‚ö° Sehr schnell (< 100ms pro Test)
- üîí Vollst√§ndig isoliert (keine Abh√§ngigkeiten)
- üéØ Fokus auf eine Klasse/Methode
- üìä Hohe Coverage (> 90%)

**Beispiele:**
- Domain Entity Tests (Konstruktoren, Methoden, Validierung)
- Application Service Tests (mit Moq-Mocks)
- Controller Tests (mit Mocked Services)

**Aktuelle Metriken:**
- Domain Tests: 203 Tests, ~625ms, 89.6% Coverage
- Application Tests: 237 Tests, ~3s, 90.52% Coverage
- API Tests: 80 Tests, ~487ms
- Web Tests: 62 Tests, ~882ms

### 2. Integration Tests

**Ziel:** Tests f√ºr Interaktionen zwischen Komponenten

**Charakteristika:**
- üóÑÔ∏è Echte Datenbank (SQLite)
- üîÑ Echte Services/Repositories
- ‚è±Ô∏è Mittlere Geschwindigkeit (< 1s pro Test)
- üéØ Fokus auf Repository/Service-Interaktionen

**Beispiele:**
- Repository Integration Tests (EF Core, SQLite)
- DbContext Tests (Entity Configuration, Relationships)
- Configuration Tests (DbContext Configuration)

**Aktuelle Metriken:**
- Infrastructure Tests: 173 Tests, ~9s, 39.16% Coverage

### 3. End-to-End (E2E) Tests

**Ziel:** Vollst√§ndige User-Journeys testen

**Charakteristika:**
- üåê Vollst√§ndiger HTTP-Stack (WebApplicationFactory)
- üóÑÔ∏è Echte Datenbank (SQLite)
- üêå Langsam (> 1s pro Test)
- üéØ Fokus auf komplette Workflows

**Beispiele:**
- Employee Web Flow (Registrierung ‚Üí Scan ‚Üí Progress)
- Admin Workflow (Login ‚Üí Dashboard ‚Üí Campaign Management)
- Campaign Lifecycle (Erstellen ‚Üí Aktivieren ‚Üí QR-Codes)

**Aktuelle Metriken:**
- Integration Tests: 37 Tests, ~8s

**Optimierungen:**
- Parallele Ausf√ºhrung: `[Parallelizable(ParallelScope.Self)]`
- Data-Driven Tests: `[TestCase]` f√ºr √§hnliche Szenarien
- Reduktion von 112 auf 37 Tests (67% Reduktion)

## üìê Coverage-Requirements

### Minimum-Anforderungen

| Projekt | Minimum Coverage | Aktuell | Status |
|---------|-----------------|---------|--------|
| **Domain** | ‚â• 80% | 89.6% | ‚úÖ Erf√ºllt |
| **Application** | ‚â• 80% | 90.52% | ‚úÖ Erf√ºllt |
| **Infrastructure** | ‚â• 60% | 39.16% | ‚ö†Ô∏è Noch nicht erreicht |

### Coverage-Verbesserungs-Strategie

1. **Domain**: ‚úÖ Abgeschlossen (89.6%)
   - Alle Entity-Konstruktoren getestet
   - Alle Entity-Methoden getestet
   - Edge Cases und Boundary Conditions abgedeckt

2. **Application**: ‚úÖ Abgeschlossen (90.52%)
   - Alle Service-Methoden getestet
   - Exception-Handling getestet
   - Edge Cases abgedeckt

3. **Infrastructure**: ‚ö†Ô∏è In Arbeit (39.16%)
   - Repository-Methoden getestet
   - DbContext-Configuration getestet
   - Noch zu testen: Migration-Klassen, weitere Config-Dateien

## üîß Test-Technologien

### Test-Framework

- **NUnit**: Haupt-Test-Framework
- **Moq**: Mocking-Framework f√ºr Unit-Tests
- **WebApplicationFactory**: In-Memory HTTP-Server f√ºr E2E-Tests
- **SQLite**: In-Memory-Datenbank f√ºr Integration-Tests

### Test-Tools

- **Coverlet**: Code-Coverage-Erfassung
- **ReportGenerator**: Coverage-Reports
- **dotnet test**: Test-Runner

## üìù Test-Naming-Konventionen

### Pattern

```
[Method]_[Condition]_[ExpectedResult]
```

### Beispiele

```csharp
[Test]
public async Task CreateCampaign_WithValidName_ShouldReturnCampaign()
{
    // Arrange, Act, Assert
}

[Test]
public async Task GetCampaignById_WithNonExistentId_ShouldReturnNull()
{
    // Arrange, Act, Assert
}

[Test]
public async Task UpdateCampaign_WithNullName_ShouldThrowArgumentException()
{
    // Arrange, Act, Assert
}
```

### Test-Klassen-Namen

```
[Entity/Service]Tests
[Entity/Service]IntegrationTests
[Workflow]IntegrationTests
```

### Beispiele

- `UserTests`
- `CampaignServiceTests`
- `FindRepositoryIntegrationTests`
- `EmployeeWebFlowIntegrationTests`

## üèÉ‚Äç‚ôÇÔ∏è Test-Ausf√ºhrung

### Lokale Ausf√ºhrung

```bash
# Alle Tests ausf√ºhren
dotnet test --verbosity minimal

# Nur Unit Tests
dotnet test tests/EasterEggHunt.Domain.Tests --verbosity minimal
dotnet test tests/EasterEggHunt.Application.Tests --verbosity minimal

# Nur Integration Tests
dotnet test tests/EasterEggHunt.Infrastructure.Tests --verbosity minimal
dotnet test tests/EasterEggHunt.Integration.Tests --verbosity minimal

# Mit Coverage
dotnet test --collect:"XPlat Code Coverage" --verbosity minimal

# Parallele Ausf√ºhrung (Standard)
dotnet test --verbosity minimal

# Sequenzielle Ausf√ºhrung (wenn n√∂tig)
dotnet test --verbosity minimal -- --no-parallel
```

### CI/CD Pipeline

- **GitHub Actions**: Automatische Test-Ausf√ºhrung bei jedem Push
- **Pre-Commit Hook**: Verhindert Commits ohne erfolgreiche Tests
- **Coverage-Reporting**: Automatische Coverage-Reports in CI

## ‚úÖ Test-Qualit√§t-Kriterien

### Erf√ºllt ‚úÖ

1. **Test-Pyramide**: 73% Unit, 22% Integration, 5% E2E
2. **Domain Coverage**: 89.6% (Ziel: ‚â•80%) ‚úÖ
3. **Application Coverage**: 90.52% (Ziel: ‚â•80%) ‚úÖ
4. **Test-Geschwindigkeit**: Gesamt ~22s f√ºr 792 Tests ‚úÖ
5. **Test-Isolation**: Alle Tests sind unabh√§ngig ‚úÖ
6. **Edge Cases**: Umfassende Edge-Case-Abdeckung ‚úÖ

### Verbesserungsbedarf ‚ö†Ô∏è

1. **Infrastructure Coverage**: 39.16% (Ziel: ‚â•60%) ‚ö†Ô∏è
   - Viele Code-Pfade in Migration-Klassen (auto-generiert)
   - Konfigurations-Dateien schwer zu testen
   - DbContext OnModelCreating private Methoden

## üìö Best Practices

### Unit Tests

1. **ARRANGE-ACT-ASSERT Pattern**
   ```csharp
   [Test]
   public void TestMethod()
   {
       // Arrange - Testdaten vorbereiten
       var campaign = new Campaign("Test", "Description", "Admin");
       
       // Act - Methode ausf√ºhren
       var result = campaign.Activate();
       
       // Assert - Ergebnis pr√ºfen
       Assert.That(campaign.IsActive, Is.True);
   }
   ```

2. **Isolation**: Keine Abh√§ngigkeiten zwischen Tests
3. **Mocking**: Nur externe Abh√§ngigkeiten mocken
4. **Edge Cases**: Boundary Conditions testen
5. **Parametrisierte Tests**: `[TestCase]` f√ºr √§hnliche Szenarien

### Integration Tests

1. **Test-Datenbank**: Jeder Test nutzt isolierte Datenbank
2. **Cleanup**: `TearDown` f√ºr Datenbank-Bereinigung
3. **Test-Base-Klasse**: `IntegrationTestBase` f√ºr gemeinsame Setup-Logik
4. **Seeding**: Test-Daten in `SetUp` erstellen
5. **Dispose**: Korrekte Ressourcen-Freigabe

### E2E Tests

1. **WebApplicationFactory**: Zentralisiert in `TestWebApplicationFactoryBase`
2. **Logging**: Reduziert auf `LogLevel.Critical` f√ºr saubere Outputs
3. **Datenbank-Isolation**: Jeder Test nutzt eigene SQLite-Datenbank
4. **Parallelisierung**: `[Parallelizable(ParallelScope.Self)]` wo m√∂glich
5. **Data-Driven**: `[TestCase]` f√ºr √§hnliche Workflows

## üêõ H√§ufige Probleme & L√∂sungen

### Problem 1: Tests sind zu langsam

**Symptom:** Test-Ausf√ºhrung dauert > 1 Minute
**L√∂sung:**
- Parallele Ausf√ºhrung aktivieren
- Unn√∂tige Integration-Tests entfernen
- In-Memory-Datenbank statt echte Datenbank

### Problem 2: Tests sind flaky

**Symptom:** Tests schlagen manchmal fehl
**L√∂sung:**
- Race Conditions identifizieren und beheben
- Timing-abh√§ngige Tests korrigieren
- Test-Isolation verbessern

### Problem 3: Niedrige Coverage

**Symptom:** Coverage < Ziel
**L√∂sung:**
- Ungetestete Methoden identifizieren
- Edge Cases hinzuf√ºgen
- Boundary Conditions testen
- Fehlerbehandlung testen

### Problem 4: Integration Tests sind zu komplex

**Symptom:** Integration Tests sind schwer zu warten
**L√∂sung:**
- In Unit-Tests umwandeln (mit Mocks)
- Test-Helper-Klassen erstellen
- Test-Daten-Factories nutzen

## üìà Metriken-Tracking

### Wichtige Metriken

1. **Test-Anzahl**: Aktuell ~792 Tests
2. **Test-Geschwindigkeit**: ~22s f√ºr alle Tests
3. **Code Coverage**: Domain 89.6%, Application 90.52%, Infrastructure 39.16%
4. **Test-Erfolgsrate**: Ziel: 100% (aktuell: 100% ‚úÖ)

### Coverage-Trends

- **Domain**: 66.4% ‚Üí 89.6% (+23.2%)
- **Application**: 68.42% ‚Üí 90.52% (+22.1%)
- **Infrastructure**: 34.04% ‚Üí 39.16% (+5.12%)

## üéì Test-Beispiele

### Domain Unit Test

```csharp
[TestFixture]
public class UserTests
{
    [Test]
    public void Constructor_WithValidName_ShouldCreateUser()
    {
        // Arrange & Act
        var user = new User("Test User");
        
        // Assert
        Assert.That(user.Name, Is.EqualTo("Test User"));
        Assert.That(user.IsActive, Is.True);
    }
}
```

### Application Service Test (mit Moq)

```csharp
[TestFixture]
public class CampaignServiceTests
{
    private Mock<ICampaignRepository> _mockRepository = null!;
    private CampaignService _service = null!;
    
    [SetUp]
    public void Setup()
    {
        _mockRepository = new Mock<ICampaignRepository>();
        _service = new CampaignService(_mockRepository.Object, _mockLogger.Object);
    }
    
    [Test]
    public async Task CreateCampaignAsync_WithValidData_ShouldCreateCampaign()
    {
        // Arrange
        var request = new CreateCampaignRequest("Test", "Description");
        var expectedCampaign = new Campaign("Test", "Description", "Admin");
        _mockRepository.Setup(r => r.AddAsync(It.IsAny<Campaign>()))
            .ReturnsAsync(expectedCampaign);
        
        // Act
        var result = await _service.CreateCampaignAsync(request);
        
        // Assert
        Assert.That(result.Name, Is.EqualTo("Test"));
        _mockRepository.Verify(r => r.AddAsync(It.IsAny<Campaign>()), Times.Once);
    }
}
```

### Integration Test

```csharp
[TestFixture]
[Category("Integration")]
public class CampaignRepositoryIntegrationTests : IntegrationTestBase
{
    [Test]
    public async Task AddAsync_WithValidCampaign_ShouldAddCampaign()
    {
        // Arrange
        await ResetDatabaseAsync();
        var campaign = new Campaign("Test", "Description", "Admin");
        
        // Act
        await CampaignRepository.AddAsync(campaign);
        await CampaignRepository.SaveChangesAsync();
        
        // Assert
        var retrievedCampaign = await CampaignRepository.GetByIdAsync(campaign.Id);
        Assert.That(retrievedCampaign, Is.Not.Null);
        Assert.That(retrievedCampaign!.Name, Is.EqualTo("Test"));
    }
}
```

### E2E Test

```csharp
[TestFixture]
[Category("Integration")]
public class EmployeeWebFlowIntegrationTests
{
    [Test]
    public async Task CompleteEmployeeWebFlow_RegistrationAndScan_Success()
    {
        // Arrange
        var factory = new ControllerTestWebApplicationFactory();
        var client = factory.CreateClient();
        
        // Act 1: Registrierung
        var registerResponse = await client.PostAsync("/api/users", 
            JsonContent.Create(new { name = "Test User" }));
        registerResponse.EnsureSuccessStatusCode();
        
        // Act 2: QR-Code scannen
        var scanResponse = await client.PostAsync("/api/finds", 
            JsonContent.Create(new { qrCodeId = 1, userId = 1 }));
        scanResponse.EnsureSuccessStatusCode();
        
        // Assert
        Assert.That(registerResponse.IsSuccessStatusCode, Is.True);
        Assert.That(scanResponse.IsSuccessStatusCode, Is.True);
    }
}
```

## üîÑ Wartung & Aktualisierung

### Regelm√§√üige Reviews

- **Monatlich**: Coverage-Trends √ºberpr√ºfen
- **Bei neuen Features**: Tests f√ºr neue Funktionalit√§t hinzuf√ºgen
- **Bei Refactorings**: Tests anpassen

### Test-Pflege

1. **Entfernen**: Unn√∂tige/Redundante Tests entfernen
2. **Konsolidieren**: √Ñhnliche Tests zusammenf√ºhren (Data-Driven)
3. **Optimieren**: Langsame Tests beschleunigen
4. **Dokumentieren**: Komplexe Tests dokumentieren

## üìö Weitere Ressourcen

- [NUnit Documentation](https://docs.nunit.org/)
- [Moq Documentation](https://github.com/moq/moq4)
- [ASP.NET Core Testing](https://docs.microsoft.com/en-us/aspnet/core/test/integration-tests)
- [Code Coverage Best Practices](https://www.jetbrains.com/help/dotnet/code-coverage.html)

---

**Letzte Aktualisierung:** Oktober 2025  
**Version:** 1.0  
**Status:** ‚úÖ Aktiv

